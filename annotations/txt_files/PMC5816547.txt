TITLE: Health professionals’ perceptions about their clinical performance and the influence of audit and feedback on their intentions to improve practice: a theory-based study in Dutch intensive care units

  ABSTRACT.BACKGROUND:
 id="Par1">Audit and feedback aims to guide health professionals in improving aspects of their practice that need it most. Evidence suggests that feedback fails to increase accuracy of professional perceptions about clinical performance, which likely reduces audit and feedback effectiveness. This study investigates health professionals' perceptions about their clinical performance and the influence of feedback on their intentions to change practice.

ABSTRACT.METHODS:
 id="Par3">We conducted an online laboratory experiment guided by Control Theory with 72 intensive care professionals from 21 units. For each of four new pain management indicators, we collected professionals' perceptions about their clinical performance; peer performance; targets; and improvement intentions before and after receiving first-time feedback. An electronic audit and feedback dashboard provided ICU's own performance, median and top 10% peer performance, and improvement recommendations. The experiment took place approximately 1 month before units enrolled into a cluster-randomised trial assessing the impact of adding a toolbox with suggested actions and materials to improve intensive care pain management. During the experiment, the toolbox was inaccessible; all participants accessed the same version of the dashboard.

ABSTRACT.RESULTS:
 id="Par4">We analysed 288 observations. In 53.8%, intensive care professionals overestimated their clinical performance; but in only 13.5%, they underestimated it. On average, performance was overestimated by 22.9% (on a 0–100% scale). Professionals similarly overestimated peer performance, and set targets 20.3% higher than the top performance benchmarks. In 68.4% of cases, intentions to improve practice were consistent with actual gaps in performance, even before professionals had received feedback; which increased to 79.9% after receiving feedback (odds ratio, 2.41; 95% CI, 1.53 to 3.78). However, in 56.3% of cases, professionals still wanted to improve care aspects at which they were already top performers. Alternatively, in 8.3% of cases, they lacked improvement intentions because they did not consider indicators important; did not trust the data; or deemed benchmarks unrealistic.

ABSTRACT.CONCLUSIONS:
 id="Par5">Audit and feedback helps health professionals to work on aspects for which improvement is recommended. Given the abundance of professionals' prior good improvement intentions, the limited effects typically found by audit and feedback studies are likely predominantly caused by barriers to translation of intentions into actual change in clinical practice.

ABSTRACT.TRIAL REGISTRATION:
 xmlns:ns0="http://www.w3.org/1999/xlink" id="Par6">ClinicalTrials.gov
NCT02922101. Registered 26 September 2016.

ABSTRACT.ELECTRONIC SUPPLEMENTARY MATERIAL:
The online version of this article (10.1186/s13012-018-0727-8) contains supplementary material, which is available to authorized users.

BODY.BACKGROUND:
 id="Par13">Audit and feedback (A&F) interventions provide health professionals with a summary of their clinical performance over a specified period of time and are a widely used approach to improve quality of care [1]. A Cochrane review of 140 A&F studies concluded that feedback is effective, but with only a median 4.3% absolute improvement (interquartile range 0.5 to 16%) [1]. The reasons behind this limited and variable effect are only partially understood, and further research into the underlying mechanisms through which A&F brings about change is needed to increase its effects [2, 3].   id="Par14">A&F is thought to work because it improves the accuracy with which health professionals self-assess their performance [4]. If they make a negative assessment of their clinical performance by comparing their performance to a target, professionals will develop intentions to improve practice [5]. Therefore, those informed by A&F may be better able to focus their time and resources available for quality improvement more efficiently on those care aspects that need it most. However, previous studies have shown that feedback messages are rejected when recipients do not trust the data, disagree with benchmarks, consider improvement unfeasible, or do not consider the clinical topic an important aspect of care quality [6–9]. An empirical study showed that health professionals ignored between a third and half of the improvement recommendations when confronted with feedback on multiple quality indicators [6]. This may indicate that health professionals already have certain perceptions about their clinical performance before receiving feedback, and that many times, feedback fails to change those perceptions. In turn, this potentially prevents professionals from developing intentions to improve their practice even if improvement is recommended, or, leads to retaining intentions to improve while there may not be room for improvement [10]. We refer to this problem as the information–intention gap. Intentions are essential for initiating behaviour [11]. A lack of correspondence between health professionals' intended improvement targets and recommended improvement targets may therefore play an important role in explaining the limited effects of A&F interventions [3, 12].   id="Par15">We designed a theory-based experiment to investigate health professionals' perceptions about their clinical performance and the influence of feedback on their intentions to change clinical practice.

BODY.METHODS.THEORETICAL FRAMEWORK:
 id="Par16">Our theoretical framework which we based on Control Theory [5] is published in the study protocol [13]. It assumes that health professionals continuously self-assess their clinical performance by comparing their performance to a target. If they make a negative assessment (i.e. perceived clinical performance < target), the theory predicts that health professionals will develop intentions to take improvement actions and continue these actions until their performance matches or exceeds the target. However, if they observe a discrepancy that is too great, or lack the skills or knowledge on how to improve, recipients may disregard the discrepancy or lower their target to make it more achievable [14, 15]. A&F may influence professionals' improvement intentions by changing their underlying perceptions about their own performance and the appropriateness of targets.

BODY.METHODS.STUDY SETTING:
Study flow. Measured and delivered variables for each of four indicators and outcome measures. We collected 288 observations (4 indicators × 72 ICU professionals). *We considered an intention to be at odds with Control Theory if participants had no intention despite a negative self-assessment (i.e. perceived performance < target) or they had improvement intention despite a positive self-assessment (i.e. perceived ICU performance ≥ target)

BODY.METHODS.PARTICIPANTS:
 id="Par18">We invited all 83 intensive care professionals who were members of the local quality improvement teams from all 21 ICUs participating in the trial. Personalised invitation emails were sent with up to two reminders. Teams usually consisted of three to five members and included intensivists, nurses, and managers.

BODY.METHODS.INTERVENTION DESCRIPTION:
 id="Par19">The dashboard provides feedback on four pain management indicators (screenshot available in Additional file 1). The indicator set was recently developed in close collaboration with ICU professionals using an extensive rating and consensus procedure. For each indicator, the dashboard lists the performance score achieved by the ICU (e.g. percentage of patients per shift whose pain is measured), the median score of all participating ICUs, the average score achieved by the top 10% best performing ICUs [16], and a performance assessment represented by a 'traffic light' coloured icon; all calculated over the most recent 3 months. Green icons (good performance) are assigned to performance scores above or slightly under the top 10% peer performance. If not green, yellow icons (room for improvement) are assigned to scores above or slightly under the median peer performance; red icons (improvement recommended) are assigned otherwise (for the precise thresholds for assigning icons we refer to the study protocol [13]). From the dashboard overview, users can drill down to see detailed performance information, using trend charts displaying their own and peer past performance over time, performance scores grouped by most relevant patient subgroups (e.g. only surgical patients; only patients during night shifts), and lists of individual patient numbers with an indication whether or not the indicator was violated during a shift. Additional static information about the indicators are available to users, namely, their operationalisation, goal, relation to quality, definitions, inclusion and exclusion criteria, type (process or outcome), and unit of observation.

BODY.METHODS.DATA COLLECTION:
 id="Par20">Data collection took place in two steps (Fig. 1). In the first step, the description of the four indicators and their static information were presented, but measured performance information was withheld. Participants were asked to estimate for each indicator their own ICU's performance score (perceived clinical performance; range 0–100%) and the average score across Dutch ICUs (perceived peer performance; range 0–100%); fill out the minimum performance score they would consider 'good' performance (target; range 0–100%); and whether or not they would perform actions to improve upon the selected indicator (intention to improve practice; range yes/no). If the underlying Control Theory hypothesis was violated (e.g. negative self-assessment but no intention to improve), participants were asked to explain their choice using a predefined list of reasons or in free text (Additional file 2). The provided predefined reasons were developed guided by theoretical behaviour change frameworks [11, 17] and previous work [6, 18].   id="Par21">In the second step, participants were additionally exposed to all detailed performance information for the indicators including their own current performance score; own past performance scores; and the median and top 10% peer performance scores. Like in step 1, participants were asked—but this time based on the information at hand—what their performance target was (range; 0–100%) and if they intended to improve practice (range yes/no). If improvement intentions did not correspond with the improvement recommendation presented in the dashboard (e.g. room for improvement but no intention to improve), participants were again asked to explain their choice using the same list of predefined reasons as in step 1, extended with three reasons relating to feedback rejection (Additional file 2) or free text.   id="Par22">Finally, if there were discrepancies between improvement intentions in the first and second step (e.g. initially participants did not develop intention to improve on a specific indicator, but after receiving feedback they did), participants were asked what feedback elements drove them to change (measured performance score were higher/lower than expected; benchmarks were higher/lower than expected; there was a green/yellow/red icon; other [free text]).

BODY.METHODS.OUTCOME MEASURES:
 id="Par23">The primary outcome was the proportion of improvement intentions set by participants that corresponded with the improvement recommendations. We considered an improvement intention to correspond with the recommendation when a participant reported an intention to improve upon an indicator with room for improvement (i.e. red or yellow icon), or had no intention to improve an indicator without room for improvement (i.e. green icon). Secondary outcomes were the difference between perceived clinical performance (before receiving feedback) and measured performance; difference between performance targets set by participants (before receiving feedback) and the external targets determined by the feedback; change in performance targets after receiving feedback; and reasons for not intending to improve on indicators despite a negative self-assessment (i.e. perceived clinical performance < target) and vice versa.

BODY.METHODS.STATISTICAL ANALYSIS:
 id="Par24">Descriptive statistics were calculated as appropriate for all variables of interest. We compared performance scores and targets chosen by participants (i.e. perceived clinical performance; perceived peer performance; target) to those that resulted from the audit (i.e. actual clinical performance; median peer performance; external target [top 10% peer performance]), and calculated Pearson's correlations. We used t tests to test whether the differences were significant. To assess the influence of feedback on the correspondence of participants' improvement intentions with the improvement recommendations we used mixed-effects logistic regression analysis, using a binary 'feedback received' covariate. We added a random intercept for 'participating professional' to adjust for correlations between repeated observations within participants, added random intercepts for 'ICU', and 'quality indicator' to adjust for clustering effects within ICUs and around quality indicators. We additionally assessed whether clinical performance perceptions and improvement intentions differed between professional roles (i.e. nurses, intensivists, managers, or others) for each quality indicator (Additional file 3).

BODY.RESULTS:
Characteristics of individual intensive care professionals invited to participate in the study

BODY.RESULTS.CLINICAL PERFORMANCE PERCEPTIONS AND IMPROVEMENT INTENTIONS BEFORE RECEIVING FEEDBACK:
Actual performance and recommendations (upper rows) and perceived clinical performance and intentions to improve practice (lower rows)   id="Par27">In 235 cases (81.6%), the presence or absence of improvement intentions was consistent with our theoretical framework based on the negative or positive self-assessment participants made by comparing perceived performance to their target. Participants had the intention to improve their performance on 230 (79.9%) indicator values; 194 (84.3%) of these followed from a negative self-assessment. In the remaining 36 (15.7%) cases, participants positively self-assessed but still had the intention to improve their performance because they considered the indicator an essential aspect of intensive care quality that should always be targeted for improvement (n = 29) and that they deemed it easy to improve on the indicator (n = 7). There were 58 (20.1%) indicator values for which participants did not have the intention to improve their performance; 41 (70.7%) of these followed from a positive self-assessment. In the remaining 17 (29.3%) cases, participants negatively self-assessed but deemed improvement unfeasible (n = 10), considered the indicator not an important aspect of intensive care (n = 6), or lacked time and resources (n = 1).

BODY.RESULTS.CORRESPONDENCE OF CLINICAL PERFORMANCE PERCEPTIONS AND IMPROVEMENT INTENTIONS WITH ACTUAL PERFORMANCE AND IMPROVEMENT RECOMMENDATIONS:
Scatter plot of intensive care professionals' perceived clinical performance compared to their actual performance (above diagonal line = overestimation; below = underestimation)  Correspondence between intensive care professionals' intentions and improvement recommendations before and after receiving feedback   id="Par30">In the 217 cases in which there was room for improvement, participants who had the intention to improve overestimated their own performance similarly to those who did not (30.1 versus 36.7% overestimation; p = 0.247), but did set higher targets relative to the external targets (32.3 versus 21.1% higher than the external targets; p = 0.012). In the other 71 cases of 'good performance', both participants who did and those who did not have the intention to improve similarly overestimated performance (4.6% underestimation versus 5.2% overestimation; p = 0.248) and set similar targets relative to the external targets (16.2 versus 14.3% higher than the external targets; p = 0.823).

BODY.RESULTS.CHANGE IN IMPROVEMENT INTENTIONS AND PERFORMANCE TARGETS AFTER RECEIVING FEEDBACK:
Bar chart of intensive care professionals' intentions to improve practice before and after receiving clinical performance feedback   id="Par32">In total, participants ignored 58 (20.1%) of the improvement recommendations provided by the feedback. For 40 (56.3%) 'good performance' indicator values, they still had the intention to improve because they thought their performance score was too low (n = 20), considered the indicator an essential aspect of intensive care quality that should always be targeted for improvement (n = 14), or deemed it easy to improve on the indicator (n = 4). For 18 (8.3%) 'room for improvement' or 'improvement recommended' indicator values, participants had no intention to improve because they considered their measured performance score inaccurate (n = 7); the indicator not an important aspect of intensive care (n = 6); benchmarks unrealistic or unachievable (n = 3); or improvement unfeasible (n = 2).   id="Par33">Participants did downward adjust their targets to a median 90% (IQR, 75 to 90). These new targets were on average 13.9% (95% CI, 10.1 to 17.67) higher than the external targets; their correlation was stronger (r = 0.53, p≤ 0.001) than before receiving feedback. There were no significant differences in targets and intentions between nurses, intensivists, and managers (Additional file 3).

BODY.DISCUSSION:
 id="Par34">Our study showed that 53.8% of the time, intensive care professionals substantially overestimated their clinical performance; only 13.5% of the time they underestimated it. Professionals also overestimated peer performance and set their targets much higher than the external targets used in this study. In 81.6% of cases, professionals' improvement intentions could be predicted by Control Theory [5] based on the performance self-assessments professionals had made by comparing their perceived performance score to their target. Already 68.4% of those intentions corresponded with the improvement recommendations even before they had received feedback on their clinical performance; which further increased to 79.9% after receiving feedback. The feedback made it more than twice as likely that professionals' intentions followed the improvement recommendations. Our findings therefore seem to confirm that feedback increases the accuracy with which health professionals self-assess their performance; which is the principal hypothesised mechanism through which A&F is thought to work [1, 4].   id="Par35">The intensive care professionals attributed changes in their intentions particularly to the performance score they received, not to the median or top 10% peer performance benchmarks. This suggests that professionals did adopt new insights about their own performance, but less so about appropriate performance targets. Although professionals in this study did slightly downward adjust their targets based on the feedback they received, they still set them higher than the top 10% peer performance. As a result participants had the intention to improve half of the cases in which they were already top performers. Although improvement could still be achievable, setting reasonable targets should help professionals to prioritise their improvement activities. Study periods in A&F trials are often limited, and health professionals typically have to choose between multiple care aspects to focus on [19, 20]. Many hypotheses exist about how performance comparators may trigger more reactions to the feedback, such as using achievable benchmarks instead of medians [21]. At the moment, there is conflicting evidence about this hypothesis [16, 22], and our results demonstrate that intensive care professionals often aim for something higher regardless of which comparator is delivered.   id="Par36">In 8.3% of cases, intensive care professionals had no intention to improve upon quality indicators for which the feedback recommended improvement. In comparison, in a similar experiment in cardiac rehabilitation, professionals ignored one third of the cases for which the feedback recommended improvement [6]. The difference might relate to the cognitive load for health professionals which was smaller in the current study in terms of the number and variety of targeted behaviours [21, 23], and other differences in design and content of the feedback. In our study, professionals rejected feedback because they considered some quality indicators as not an important aspect of intensive care, did not trust the measured own performance score, or considered the benchmarks unrealistic.

BODY.DISCUSSION.STRENGTHS AND LIMITATIONS:
 id="Par37">The principal strength of our study is the extensive use of Control Theory [5] as a basis for our study design. Although there is growing recognition that theory should play a central role in the design and evaluation of A&F interventions [2], explicit use of theory remains scarce [24, 25]. We tested the hypothesis that A&F increases the correspondence between health professionals' intentions and improvement recommendations; this hypothesis is typically assumed to be true in A&F studies but has not, to the best of our knowledge, been evaluated empirically. Which threshold is used to determine such recommendations is a design choice to be made by A&F designers; in this study, we used top 10% peer performance. Using a different target would lead to a different correspondence between intentions and recommendations. However, it would unlikely affect the relationship we found between providing the feedback and professionals changing their intentions.   id="Par38">The generalisability of our findings with respect to health professionals' improvement intentions may be limited due to the clinical topic and setting, namely pain management in ICUs. ICU professionals traditionally work in a data-rich environment and are early adopters of A&F systems. This could have resulted in our participants being more experienced and set higher targets than health professionals from other domains. At the same time the extent to which indicators are under ICU professionals' control may differ between professionals. For example, performing pain measurements is typically a nursing task, while intervening to achieve acceptable pain scores falls under the responsibility of intensivists. Therefore, participants might have estimated their ICU's performance more accurately and set more informed targets if we would have asked them to respond as a team. The fact that we found no significant differences in performance estimations or improvement intentions between professional roles for any of the indicators might reflect the strong team mentality and shared responsibilities in ICU patient care. As this might be different in other settings, it is however a pertinent point to consider whether feedback actually reaches the health professionals whose behaviour is targeted for change and whether the recommendations arising from the feedback make it clear who is responsible for taking action [26].   id="Par39">We developed the dashboard carefully considering the latest evidence, theory, and design suggestions and involved intensive care professionals in the process [13]. This likely contributed to the fact that in 91.7% of cases, feedback convinced participants to change practice. The indicator set was developed in close collaboration with experts and pilot tested to ensure that the indicators are consistent with professionals' goals and priorities and under their control [13, 23]. It seems however inevitable that some professionals have concerns about the importance of certain indicators. Lack of trust in data quality, often identified as a barrier to change [15, 27], might in this study have particularly related to the perception that the targeted behaviour is performed in practice (e.g. patients' pain is measured each shift) but not recorded electronically. We undertook various data quality assurance efforts [28] and provided patient-level data and subgroup analyses to increase transparency [29]. More intensive measures might be required to ensure professionals recognise the importance of indicators and trust in the data, e.g. through verbal feedback and when feedback is discussed by teams rather than individuals [1, 6]. In addition we delivered multiple performance comparators to prevent benchmarks being perceived as unrealistically high; namely median, top 10% peer performance, and own past performance. Delivering multiple comparators is at odds with recent suggestions for A&F design because it could create ambiguity in what should be achieved [23]. Our findings however show that multiple comparators worked well despite possible ambiguities. To reduce ambiguity, we delivered traffic light colour-coded benchmark comparisons.   id="Par40">We conducted our study with intensive care professionals in a laboratory setting shortly before enrolment in a cRCT in which they received feedback on the four new pain management indicators for the first time. By aligning the experiment with the cRCT, we were able to deliver professionals' real clinical performance data and obtain a high response rate of nearly 90%, while using the same dashboard and data collection methods. Laboratory experiments in the field of A&F are scarce but enable a great opportunity to gain detailed insights into professionals' decision making that allows us to advance implementation science while reducing research waste [30].

BODY.DISCUSSION.UNANSWERED QUESTIONS AND FUTURE RESEARCH:
 id="Par41">Given the great presence of health professionals' intentions to improve the care they provide, the limited effectiveness often found in A&F studies is likely the result of barriers to translating intentions into actual change in clinical practice. Future research should focus on overcoming those barriers, and less so on convincing professionals to improve practice. The cRCT following the current study will (1) reveal whether teams target less indicators for improvement in practice, e.g. due to prioritisation or resource limitations, and (2) determine the effectiveness of augmenting the dashboard with an action implementation toolbox to address the gap between intentions and actions [13].

BODY.CONCLUSION:
 id="Par42">Health professionals often overestimate their clinical performance and rarely underestimate it. In addition, they are typically optimistic about the performance of peers and achievable targets. Nevertheless, their prior intentions to improve practice often already correspond to actual gaps in clinical performance. Feedback further increases this correspondence because it allows professionals to self-assess their performance more accurately. However, professionals still have a tendency to want to improve upon care aspects at which they are already top performers. In a tenth of cases, professionals lack improvement intentions because they do not consider some indicators an essential aspect of care quality, do not trust the data, or deem the benchmarks unrealistic. Given the abundance of health professionals' good improvement intentions, it is likely that the limited effects typically found by audit and feedback studies are predominantly caused by barriers to translation of intentions into actual change in clinical practice. Interventions should focus on overcoming those barriers, and less so on convincing professionals to improve practice.

BODY.ADDITIONAL FILES:
Screenshot dashboard (translated from Dutch). (PDF 137 kb)