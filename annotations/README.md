## File Types
There are 6 different files contained in this zip file:
- The file annotations_merged.csv is a combination of the data found in points
- The file annotations_pilot_run.csv contains data annotated, and verified by doctors, but with prompts generated by @elehman16 (an undergrad at Northeastern University).
- The file annotations_doctor_generated.csv contains data annotated, and verified, soley by doctors. This file only has information concerning the valid answers and reasonings for a specific promptID.
- The file prompts_merged.csv is a combination of the data found in points 5. and 6.
- The file prompts_pilot_run.csv contains prompts generated by @elehman16. This file only contains the promptID and prompt information.
- The file prompts_doctor_generated.csv contains prompts generated soley by doctors.

## File Description (Annotations):
- Annotations: The annotation files consist of the following headings: UserID, PromptID, PMCID, Valid Label, Valid Reasoning, Label, Annotations, Label Code, In Abstract, Start Evidence, End Evidence.
- UserID: UserID is correlated to an ID of which doctor found the 'Label' and 'Annotations' column.
- PromptID: PromptID determines which prompt the doctor is answering. The PromptID is also given in the prompt-csv files, in which a lookup can be used to find the corresponding outcome/intervention/comparator.
- PMCID: This is the ID that we use to identify the articles. In order to find the correct article used, simply attach "PMC" + PMCID + '.nxml' and search within the xml_files folder.
- Valid Label: This value will be either a 0/1. This will determine if the verifier certfies the multiple-choice response of the annotator. '0' correlates to a rejection, which '1' indicates acception.
- Valid Reasoning: This value will be either a 0/1. This will determine if the verifier certfies the multiple-choice response of the annotator. '0' correlates to a rejection, which '1' indicates acception.
- Label: This value will have a string value of 'significantly increased', 'significantly decreased', 'no significant difference' or 'invalid prompt.' This corresponds to the response that the annotator answered for the given PromptID.
- Annotations: This value is a segment of strings, delimited by ",". This section consists of portions of the text that the annotator cited as to why they selected the label that they did.
- Label Code: This is simply an integer version of the label. '0' corresponds to 'no significant difference', '1' corresponds to 'significantly increased', and '-1' corresponds to 'significantly decreased'.
- In Abstract: This column consists of responses of '0' and '1'. This column reads '1' if the annotator got the answer from the abstract, and '0' if he or she used more than the abstract in order to answer the question.
- Start Evidence: This column represents what index in the text that the “reasoning” from this row starts at (this is inclusive). 
- End Evidence: This column represents what index in the text that the “reasoning” from this row ends at (this is also inclusive). 
- Evidence Start Plain Text: This column represents what index in the text that the “reasoning” from this row starts at (this is inclusive). However, this differs from previous 'Evidence Start' column since it relies on the plain-text version of the document, rather than the XML.
- Evidence End Plain Text: This column represents what index in the text that the “reasoning” from this row ends at (this is also inclusive). However, this differs from previous 'Evidence End' column since it relies on the plain-text version of the document, rather than the XML.
- Note: Some prompts will have 2 answers by a single doctor. This is because they might cite 2 different pieces of evidence. To properly identify this, look for rows with the same 'PromptID' and also the same 'UserID'.

## Article Types (XML vs. TXT): 
We provide two different formats to read the article from. One is the XML format, that the article reader is able to parse through. The offsets (column headers 'Evidence Start', and 'Evidence End') listed in the annotations.csv files are based on the output from the article_reader reading the XML file. 
The other is a plaintext (extension of *.txt), where we have preprocessed the XMLs. The offsets listed in the 'Evidence Start Plain Text', and 'Evidence End Plain Text' can be used right after reading the text from the .txt file. Please note that the tables in this format are particularly hard to read. Often, the offsets of table extracted information are not listed. 

## File Description (Prompts):
- PromptID: Like previously stated, this is an ID given to this specific row, including the PMCID, outcome, intervention and comparator.
- PMCID: This is the ID that we use to identify the articles. In order to find the correct article used, simply attach "PMC" + PMCID + '.nxml' and search within the xml_files folder.
- Outcome/Intervention/Comparator: The outcome/intervention/comparator columns represent the fill-in-the-blank inputs for the following prompt formed: With respect to outcome, characterize the reported difference between intervention and those receiving comparator.
