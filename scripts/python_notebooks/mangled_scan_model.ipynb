{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mangled_scan_model.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "vQUL5X95D_KR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "65c4f510-b241-41b7-9a7c-8b4b35552247"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "!cp \"/content/drive/My Drive/Colab Notebooks/PubMed-w2v.bin\" \"/content/PubMed-w2v.bin\"\n",
        "!cp \"/content/drive/My Drive/Colab Notebooks/scan_model.pth\" \"/content/scan_model.pth\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "'Copy of span-search (1).ipynb'   error_log.gdoc   run_model.ipynb\n",
            "'Copy of span-search.ipynb'\t  PubMed-w2v.bin   scan_model.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xN0V5X0wELTO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "de631c9a-0dc9-4036-ff1a-fe26ab86081e"
      },
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!pip install -q xlrd\n",
        "!git clone https://a80b7012a5c512ec3c6cb546626348b891f4f77f@github.com/bwallace/evidence-inference --branch \"span-location\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "fatal: destination path 'evidence-inference' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FkZVOGV-EPIM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "05b123a6-3bf3-4355-decb-26ef86faf74c"
      },
      "cell_type": "code",
      "source": [
        "%cd /content/evidence-inference/\n",
        "%mkdir embeddings\n",
        "%mv /content/PubMed-w2v.bin /content/evidence-inference/embeddings"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/evidence-inference\n",
            "mkdir: cannot create directory ‘embeddings’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qDvryrM5EVli",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m6MI5nGcEZ9o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1091
        },
        "outputId": "0037c8b2-6422-4520-cf3b-8c944db0d0d8"
      },
      "cell_type": "code",
      "source": [
        "%cd /content/evidence-inference\n",
        "!git config --global user.email \"lehman.e@husky.neu.edu\"\n",
        "!git pull origin span-location\n",
        "!pip install gensim\n",
        "!pip install cloudpickle\n",
        "!pip install spacy\n",
        "!python -m spacy download en"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/evidence-inference\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 5 (delta 4), reused 5 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (5/5), done.\n",
            "From https://github.com/bwallace/evidence-inference\n",
            " * branch            span-location -> FETCH_HEAD\n",
            "   544c5bc..3df79e2  span-location -> origin/span-location\n",
            "Updating 544c5bc..3df79e2\n",
            "Fast-forward\n",
            " evidence_inference/experiments/model_0_paper_experiment.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.4)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.7.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.57)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.10.15)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.57 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.57)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.57->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.57->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (0.6.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.0.16)\n",
            "Requirement already satisfied: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy) (2018.1.10)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.3.2)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.18.4)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n",
            "Requirement already satisfied: thinc<6.13.0,>=6.12.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.12.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.15.4)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: msgpack>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from msgpack-numpy<0.4.4->spacy) (0.5.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.10.15)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.0->spacy) (4.28.1)\n",
            "Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.0->spacy) (1.11.0)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.0->spacy) (0.9.0.1)\n",
            "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.0->spacy) (1.10.11)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.0->spacy) (0.9.0)\n",
            "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oZTlO1pmEdh8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "4eec94ea-62d9-4529-eebf-e3cf1726cf2f"
      },
      "cell_type": "code",
      "source": [
        "!python ./evidence_inference/experiments/model_0_paper_experiment.py --epochs=50 --article_sections=all --article_encoder=GRU --ico_encoder=CBoW --data_config=scan_net --scan_net_location=yes"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 2351706 words from vocab file annotations/vocab.txt\n",
            "Current configuration:  Config(article_sections='all', ico_encoder='CBoW', article_encoder='GRU', attn=False, cond_attn=False, tokenwise_attention=False, batch_size=32, attn_batch_size=32, epochs='50', attn_epochs=10, data_config='scan_net', pretrain_attention=False, tune_embeddings=False, no_pretrained_word_embeddings=False)\n",
            "Running config Config(article_sections='all', ico_encoder='CBoW', article_encoder='GRU', attn=False, cond_attn=False, tokenwise_attention=False, batch_size=32, attn_batch_size=32, epochs='50', attn_epochs=10, data_config='scan_net', pretrain_attention=False, tune_embeddings=False, no_pretrained_word_embeddings=False)\n",
            "loading pre-trained embeddings...\n",
            "tcmalloc: large alloc 1881366528 bytes == 0x2134e000 @  0x7f0d34878001 0x7f0d31c936f5 0x7f0d31cf70f1 0x7f0d31cf91ef 0x7f0d31d90698 0x5030d5 0x507641 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x501b2e 0x591461 0x54b813 0x555421 0x5a730c 0x503073 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "tcmalloc: large alloc 3762733056 bytes == 0x9a18a000 @  0x7f0d34878001 0x7f0d31c936f5 0x7f0d31cf70f1 0x7f0d31cf91ef 0x7f0d31d90698 0x5030d5 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x501b2e 0x591461 0x54b813 0x555421 0x5a730c 0x503073 0x507641 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859\n",
            "tcmalloc: large alloc 1881366528 bytes == 0x1b722c000 @  0x7f0d348761e7 0x7f0d31c935b1 0x7f0d31cf7178 0x7f0d31cfa8dd 0x7f0d31cfae55 0x7f0d31d91351 0x5030d5 0x507641 0x504c28 0x501ba7 0x5a36f1 0x544c72 0x5553b5 0x5a730c 0x503073 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x501b2e 0x591461 0x54b813 0x555421 0x5a730c 0x503073 0x507641 0x504c28 0x502540 0x502f3d\n",
            "tcmalloc: large alloc 1881366528 bytes == 0x227462000 @  0x7f0d34858b6b 0x7f0d34878379 0x7f0d0cfe1796 0x7f0d0cfe1b90 0x7f0d0cfe7f21 0x7f0d0cfec45f 0x7f0d0d05e328 0x7f0d0d05f671 0x7f0d0cecfef6 0x7f0d0cda059a 0x7f0d0cf8e929 0x7f0d0cdf4aa8 0x7f0d14d8fb1b 0x7f0d14d9241e 0x7f0d1510bcfb 0x5553b5 0x5a730c 0x503073 0x506859 0x504c28 0x501b2e 0x591461 0x54b813 0x555421 0x5a730c 0x503073 0x507641 0x504c28 0x502540 0x502f3d 0x506859\n",
            "done.\n",
            "freezing word embedding layer!\n",
            "tcmalloc: large alloc 1881366528 bytes == 0x2134e000 @  0x7f0d34878001 0x7f0d31c936f5 0x7f0d31cf70f1 0x7f0d31cf91ef 0x7f0d31d90698 0x5030d5 0x507641 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x501b2e 0x591461 0x54b813 0x555421 0x5a730c 0x503073 0x506859 0x504c28 0x502540 0x502f3d 0x506859\n",
            "tcmalloc: large alloc 3762733056 bytes == 0x95188000 @  0x7f0d34878001 0x7f0d31c936f5 0x7f0d31cf70f1 0x7f0d31cf91ef 0x7f0d31d90698 0x5030d5 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x501b2e 0x591461 0x54b813 0x555421 0x5a730c 0x503073 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641\n",
            "Traceback (most recent call last):\n",
            "  File \"./evidence_inference/experiments/model_0_paper_experiment.py\", line 56, in <module>\n",
            "    main()\n",
            "  File \"./evidence_inference/experiments/model_0_paper_experiment.py\", line 45, in main\n",
            "    results = generate_paper_results(configs)\n",
            "  File \"/content/evidence-inference/evidence_inference/experiments/model_0_paper_experiments.py\", line 724, in generate_paper_results\n",
            "    results = run(real_train_Xy, real_val_Xy, real_test_Xy, inference_vectorizer, mangle_method, current_config, cache=cache)\n",
            "  File \"/content/evidence-inference/evidence_inference/experiments/model_0_paper_experiments.py\", line 210, in run\n",
            "    train_Xy, val_Xy, test_Xy = mangle_method(real_train_Xy, real_val_Xy, real_test_Xy, inference_vectorizer)\n",
            "  File \"/content/evidence-inference/evidence_inference/experiments/model_0_paper_experiments.py\", line 106, in scan_net_preprocess\n",
            "    sn = load_model_scan(inference_vectorizer)\n",
            "  File \"/content/evidence-inference/evidence_inference/experiments/model_0_paper_experiments.py\", line 74, in load_model_scan\n",
            "    sn.load_state_dict(torch.load(loc))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 356, in load\n",
            "    f = open(f, 'rb')\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'yes'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}